{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "do-cGX9L1Drl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "'C:/Users/Adithya/Desktop/ds',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('C:/Users/Adithya/Desktop/ds',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "ChLOMUyM1NhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "x = Flatten()(vgg.output) #Output obtained on vgg16 is now flattened.\n",
        "prediction = Dense(41, activation='softmax')(x)\n",
        "#Creating model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4webxN-Q13a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(training_set, validation_data=test_set, epochs=20, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tac8neXO16u1",
        "outputId": "6c1c4776-98e4-4dc2-a401-793cae067996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 31s 22s/step - loss: 1.2767 - accuracy: 0.6695 - val_loss: 0.8483 - val_accuracy: 0.6695\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.8110 - accuracy: 0.6695 - val_loss: 0.5518 - val_accuracy: 0.7797\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 28s 19s/step - loss: 0.6245 - accuracy: 0.7542 - val_loss: 0.4838 - val_accuracy: 0.8475\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.6081 - accuracy: 0.8220 - val_loss: 0.4749 - val_accuracy: 0.8220\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.5228 - accuracy: 0.8136 - val_loss: 0.3518 - val_accuracy: 0.9068\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.3414 - accuracy: 0.8983 - val_loss: 0.2543 - val_accuracy: 0.9153\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.3586 - accuracy: 0.8898 - val_loss: 0.2721 - val_accuracy: 0.9153\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.3292 - accuracy: 0.9237 - val_loss: 0.1543 - val_accuracy: 0.9915\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 28s 19s/step - loss: 0.2391 - accuracy: 0.9661 - val_loss: 0.1494 - val_accuracy: 0.9915\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 28s 19s/step - loss: 0.2559 - accuracy: 0.9576 - val_loss: 0.1357 - val_accuracy: 0.9746\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.2228 - accuracy: 0.9576 - val_loss: 0.1225 - val_accuracy: 0.9915\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.1611 - accuracy: 0.9831 - val_loss: 0.1210 - val_accuracy: 0.9915\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.1491 - accuracy: 0.9915 - val_loss: 0.0999 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.1757 - accuracy: 0.9661 - val_loss: 0.0789 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 28s 19s/step - loss: 0.1464 - accuracy: 0.9831 - val_loss: 0.0628 - val_accuracy: 0.9915\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 27s 18s/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 28s 19s/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 28s 20s/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 28s 18s/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Leaf.h5\")"
      ],
      "metadata": {
        "id": "fTRuEsaSCfZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e02ff2d-c50e-43d5-f43e-475210c3041d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Adithya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('Leaf.h5')"
      ],
      "metadata": {
        "id": "oZekJ8z_DHQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img= image.load_img(r'C:\\Users\\Adithya\\Desktop\\ds\\bird eye spot\\IMG_20220503_154108.jpg', target_size=(224,224))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "output=np.argmax(model.predict(img_data), axis=1)\n",
        "index=['Aloevera','Amla','Amruthaballi','Arali','ashoka','Badipala','Balloon_Vine','Bamboo','Beans','Betel','Bhrami','Bringaraja','Castor','Catharanthus','Chilli','Citron lime (herelikai)','Coffee','Coriender','Curry','Eucalyptus','Gasagase','Ginger','Guava','Astma_weed','Hibiscus','Kohlrabi','Insulin','Honge','Lantana','Lemon','Lemongrass','Marigold','Mint','Neem','Nelavembu','Pepper','Tulsi','Turmeric','Ashoka','camphor','kepala']\n",
        "\n",
        "result=str(index[output[0]])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQBdLJD2DkHk",
        "outputId": "5c7c0e2f-6c50-4ccc-fd48-1f3ea2a2a27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 481ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bird eye spot'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}